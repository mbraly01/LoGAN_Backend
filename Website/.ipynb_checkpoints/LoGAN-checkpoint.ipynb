{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from keras.layers import Input, Reshape, Dropout, Dense, Flatten\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "counter  = 0\n",
    "\n",
    "\n",
    "\n",
    "PREVIEW_ROWS = 1\n",
    "PREVIEW_COLS = 1\n",
    "PREVIEW_MARGIN = 4\n",
    "SAVE_FREQ = 1\n",
    "# Size vector to generate images from\n",
    "NOISE_SIZE = 100\n",
    "# Configuration\n",
    "EPOCHS = 20 # number of iterations\n",
    "BATCH_SIZE = 50\n",
    "GENERATE_RES = 3\n",
    "FILE_PATH = 'train2014/test/'\n",
    "OUTPUT_PATH = 'output/'\n",
    "\n",
    "#Used\n",
    "IFP = \"/home/mbraly/python-for-byte-academy/Final_Project/Website/ifp/ifp.npy\"\n",
    "IMAGE_SHAPE = (192,192, 3)\n",
    "\n",
    "class Discriminator():\n",
    "\n",
    "    def __init__(self):\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(50, kernel_size=3, strides=2,\n",
    "        input_shape=IMAGE_SHAPE, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(100, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(ZeroPadding2D(padding=((0, 1), (0, 1))))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(200, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(400, kernel_size=3, strides=1, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(800, kernel_size=3, strides=1, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        optimizer = Adam(1.5e-4, 0.5)\n",
    "        input_image = Input(shape=IMAGE_SHAPE)\n",
    "        validity = model(input_image)\n",
    "        model = Model(input_image, validity)\n",
    "        model.compile(loss=\"binary_crossentropy\", optimizer=optimizer,\n",
    "                     metrics = [\"accuracy\"])\n",
    "        model.trainable = False\n",
    "        self.model = model\n",
    "\n",
    "class Generator():\n",
    "    def __init__(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(6 * 6 * 400, activation=\"relu\", input_dim=NOISE_SIZE))\n",
    "        model.add(Reshape((6, 6, 400)))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(400, kernel_size=3, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(400, kernel_size=3, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        for i in range(GENERATE_RES):\n",
    "            model.add(UpSampling2D())\n",
    "            model.add(Conv2D(400, kernel_size=3, padding=\"same\"))\n",
    "            model.add(BatchNormalization(momentum=0.8))\n",
    "            model.add(Activation(\"relu\"))\n",
    "        model.summary()\n",
    "        model.add(Conv2D(IMAGE_SHAPE[2], kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "        input = Input(shape=(NOISE_SIZE,))\n",
    "        generated_image = model(input)\n",
    "        self.model = Model(input, generated_image)\n",
    "\n",
    "def save_images(cnt, gen_image):\n",
    "    image_array = np.full((IMAGE_SHAPE[0] + PREVIEW_MARGIN,\n",
    "                                IMAGE_SHAPE[1] + PREVIEW_MARGIN,\n",
    "                                IMAGE_SHAPE[2]), 255, dtype=np.uint8)\n",
    "    image_count = 0\n",
    "    for row in range(1):\n",
    "        for col in range(1):\n",
    "            image_array[0: IMAGE_SHAPE[0], 0: IMAGE_SHAPE[1]] = gen_image[image_count] * 255\n",
    "            image_count += 1\n",
    "            break\n",
    "        break\n",
    "\n",
    "    if not os.path.exists(OUTPUT_PATH):\n",
    "        os.makedirs(OUTPUT_PATH)\n",
    "\n",
    "    filename = os.path.join(OUTPUT_PATH, \"img{}.jpg\".format(cnt))\n",
    "    im = Image.fromarray(image_array)\n",
    "    im.save(filename)\n",
    "\n",
    "def run():\n",
    "    training_data = np.load(IFP)\n",
    "    disc = Discriminator()\n",
    "    gen = Generator()\n",
    "    optimizer = Adam(1.5e-4, 0.5)\n",
    "    random_input = Input(shape=(NOISE_SIZE,))\n",
    "    generated_image = gen.model(random_input)\n",
    "    validity = disc.model(generated_image)\n",
    "    combined = Model(random_input, validity)\n",
    "    combined.compile(loss=\"binary_crossentropy\", optimizer=optimizer,\n",
    "                    metrics=[\"accuracy\"])\n",
    "    y_real = np.ones((BATCH_SIZE, 1))\n",
    "    y_fake = np.zeros((BATCH_SIZE, 1))\n",
    "    fixed_noise = np.random.normal(0, 1, (1, NOISE_SIZE))\n",
    "    cnt = 1\n",
    "    for epoch in range(EPOCHS):\n",
    "        idx = np.random.randint(0, training_data.shape[0], BATCH_SIZE)\n",
    "        x_real = training_data[idx]\n",
    "        noise=np.random.normal(0,1, (BATCH_SIZE, NOISE_SIZE))\n",
    "        x_fake = gen.model.predict(noise)\n",
    "        disc_metric_real = disc.model.train_on_batch(x_real, y_real)\n",
    "        disc_metric_gen = disc.model.train_on_batch(x_fake, y_fake)\n",
    "        disc_metric = 0.5 * np.add(disc_metric_real, disc_metric_gen)\n",
    "        gen_metric = combined.train_on_batch(noise, y_real)\n",
    "        if epoch % SAVE_FREQ == 0:\n",
    "            save_images(cnt, x_fake)\n",
    "            cnt += 1\n",
    "        print(\"{} epoch, Discriminator accuracy: {}, Generator accuracy: {}\".format(epoch, (100*  disc_metric[1]), (100 * gen_metric[1])))\n",
    "            # Preview image Frame"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
